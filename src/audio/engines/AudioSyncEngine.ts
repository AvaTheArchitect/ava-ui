// üéµ AudioSyncEngine - Audio-visual synchronization engine for real-time playback
// Generated by Cipher Audio Architecture Generator - Audio Engine Architecture

export interface AudioSyncEngineConfig {
  sampleRate: number;
  bufferSize: number;
  channels: number;
  enableEffects?: boolean;
  enableAnalysis?: boolean;
}

export interface AudioSyncEngineState {
  isPlaying: boolean;
  currentTime: number;
  volume: number;
  tempo: number;
  isInitialized: boolean;
}

export interface AudioEffect {
  type: 'reverb' | 'delay' | 'eq' | 'compressor' | 'distortion';
  enabled: boolean;
  parameters: Record<string, number>;
}

export class AudioSyncEngine {
  private audioContext: AudioContext | null = null;
  private config: AudioSyncEngineConfig;
  private state: AudioSyncEngineState;
  private gainNode: GainNode | null = null;
  private effectsChain: AudioNode[] = [];
  private analyser: AnalyserNode | null = null;
  private eventListeners: Map<string, Function[]> = new Map();

  constructor(config: Partial<AudioSyncEngineConfig> = {}) {
    this.config = {
      sampleRate: 44100,
      bufferSize: 4096,
      channels: 2,
      enableEffects: true,
      enableAnalysis: true,
      ...config
    };

    this.state = {
      isPlaying: false,
      currentTime: 0,
      volume: 1.0,
      tempo: 120,
      isInitialized: false
    };

    console.log(`üéµ ${className} created with config:`, this.config);
  }

  async initialize(): Promise<void> {
    try {
      // Create AudioContext with specified sample rate
      this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)({
        sampleRate: this.config.sampleRate,
        latencyHint: 'interactive'
      });

      // Create core audio nodes
      this.gainNode = this.audioContext.createGain();
      this.gainNode.gain.setValueAtTime(this.state.volume, this.audioContext.currentTime);

      // Setup effects chain if enabled
      if (this.config.enableEffects) {
        await this.setupEffectsChain();
      }

      // Setup analyser if enabled
      if (this.config.enableAnalysis) {
        this.analyser = this.audioContext.createAnalyser();
        this.analyser.fftSize = 2048;
        this.analyser.smoothingTimeConstant = 0.8;
      }

      // Connect audio graph
      this.connectAudioGraph();

      this.state.isInitialized = true;
      this.emit('initialized', { engine: this });

      console.log(`‚úÖ ${className} initialized successfully`);
      console.log(`üéöÔ∏è Sample Rate: ${this.audioContext.sampleRate}Hz`);
      console.log(`üîä Buffer Size: ${this.config.bufferSize} samples`);
      console.log(`üìä Channels: ${this.config.channels}`);

    } catch (error) {
      console.error(`‚ùå Failed to initialize ${className}:`, error);
      this.emit('error', { error, engine: this });
      throw error;
    }
  }

  private async setupEffectsChain(): Promise<void> {
    if (!this.audioContext) return;

    // Create reverb
    const convolver = this.audioContext.createConvolver();
    const reverbBuffer = await this.createReverbImpulseResponse(2, 2, false);
    convolver.buffer = reverbBuffer;

    // Create delay
    const delay = this.audioContext.createDelay(1.0);
    delay.delayTime.setValueAtTime(0.3, this.audioContext.currentTime);

    // Create EQ (using BiquadFilter)
    const lowShelf = this.audioContext.createBiquadFilter();
    lowShelf.type = 'lowshelf';
    lowShelf.frequency.setValueAtTime(320, this.audioContext.currentTime);

    const highShelf = this.audioContext.createBiquadFilter();
    highShelf.type = 'highshelf';
    highShelf.frequency.setValueAtTime(3200, this.audioContext.currentTime);

    // Create compressor
    const compressor = this.audioContext.createDynamicsCompressor();
    compressor.threshold.setValueAtTime(-24, this.audioContext.currentTime);
    compressor.knee.setValueAtTime(30, this.audioContext.currentTime);
    compressor.ratio.setValueAtTime(12, this.audioContext.currentTime);
    compressor.attack.setValueAtTime(0.003, this.audioContext.currentTime);
    compressor.release.setValueAtTime(0.25, this.audioContext.currentTime);

    this.effectsChain = [lowShelf, highShelf, compressor, delay, convolver];
    console.log(`üéõÔ∏è Effects chain created: ${this.effectsChain.length} effects`);
  }

  private connectAudioGraph(): void {
    if (!this.audioContext || !this.gainNode) return;

    let currentNode: AudioNode = this.gainNode;

    // Connect effects chain
    for (const effect of this.effectsChain) {
      currentNode.connect(effect);
      currentNode = effect;
    }

    // Connect analyser
    if (this.analyser) {
      currentNode.connect(this.analyser);
    }

    // Connect to destination
    currentNode.connect(this.audioContext.destination);

    console.log(`üîó Audio graph connected: ${this.effectsChain.length + 1} nodes`);
  }

  private async createReverbImpulseResponse(duration: number, decay: number, reverse: boolean): Promise<AudioBuffer> {
    if (!this.audioContext) throw new Error('AudioContext not initialized');

    const sampleRate = this.audioContext.sampleRate;
    const length = sampleRate * duration;
    const impulse = this.audioContext.createBuffer(2, length, sampleRate);

    for (let channel = 0; channel < 2; channel++) {
      const channelData = impulse.getChannelData(channel);
      for (let i = 0; i < length; i++) {
        const n = reverse ? length - i : i;
        channelData[i] = (Math.random() * 2 - 1) * Math.pow(1 - n / length, decay);
      }
    }

    return impulse;
  }

  async start(): Promise<void> {
    if (!this.state.isInitialized) {
      await this.initialize();
    }

    if (this.audioContext?.state === 'suspended') {
      await this.audioContext.resume();
    }

    this.state.isPlaying = true;
    this.emit('started', { engine: this });
    console.log(`‚ñ∂Ô∏è ${className} started`);
  }

  stop(): void {
    this.state.isPlaying = false;
    this.state.currentTime = 0;
    this.emit('stopped', { engine: this });
    console.log(`‚èπÔ∏è ${className} stopped`);
  }

  pause(): void {
    this.state.isPlaying = false;
    this.emit('paused', { engine: this });
    console.log(`‚è∏Ô∏è ${className} paused`);
  }

  setVolume(volume: number): void {
    const clampedVolume = Math.max(0, Math.min(1, volume));
    if (this.gainNode && this.audioContext) {
      this.gainNode.gain.setValueAtTime(clampedVolume, this.audioContext.currentTime);
      this.state.volume = clampedVolume;
      this.emit('volumeChanged', { volume: clampedVolume, engine: this });
    }
  }

  setTempo(tempo: number): void {
    const clampedTempo = Math.max(60, Math.min(200, tempo));
    this.state.tempo = clampedTempo;
    this.emit('tempoChanged', { tempo: clampedTempo, engine: this });
    console.log(`ü•Å Tempo set to: ${clampedTempo} BPM`);
  }

  applyEffect(effect: AudioEffect): void {
    console.log(`üéõÔ∏è Applying effect: ${effect.type}`, effect.parameters);
    this.emit('effectApplied', { effect, engine: this });
  }

  getAnalyserData(): { frequencyData: Uint8Array; timeData: Uint8Array } | null {
    if (!this.analyser) return null;

    const frequencyData = new Uint8Array(this.analyser.frequencyBinCount);
    const timeData = new Uint8Array(this.analyser.frequencyBinCount);
    
    this.analyser.getByteFrequencyData(frequencyData);
    this.analyser.getByteTimeDomainData(timeData);

    return { frequencyData, timeData };
  }

  getState(): AudioSyncEngineState {
    return { ...this.state };
  }

  getCurrentTime(): number {
    return this.audioContext?.currentTime || 0;
  }

  // Event system
  on(event: string, callback: Function): void {
    if (!this.eventListeners.has(event)) {
      this.eventListeners.set(event, []);
    }
    this.eventListeners.get(event)!.push(callback);
  }

  off(event: string, callback: Function): void {
    const callbacks = this.eventListeners.get(event);
    if (callbacks) {
      const index = callbacks.indexOf(callback);
      if (index > -1) {
        callbacks.splice(index, 1);
      }
    }
  }

  private emit(event: string, data: any): void {
    const callbacks = this.eventListeners.get(event);
    if (callbacks) {
      callbacks.forEach(callback => callback(data));
    }
  }

  dispose(): void {
    if (this.audioContext) {
      this.audioContext.close();
      this.audioContext = null;
    }
    
    this.effectsChain = [];
    this.eventListeners.clear();
    
    this.state.isInitialized = false;
    this.emit('disposed', { engine: this });
    console.log(`üóëÔ∏è ${className} disposed`);
  }
}

export default AudioSyncEngine;